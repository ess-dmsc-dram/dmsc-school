{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting data with `easyscience`\n",
    "\n",
    "The `easyscience` library is designed to enable model-dependent analysis, using a pure Python interface, and give access to a range of optimization algorithms. \n",
    "It is possible to analyse any data for which there is a closed-form mathematical description (i.e., a mathematical model) with parameters to be refined. \n",
    "\n",
    "This short demonstration will show how `easyscience` can be used to analyse the toy problem of data following a quadratic relationship. \n",
    "We manufacture some quadratic data to work with below. \n",
    "````{margin}\n",
    "```{note}\n",
    "We set the random seed to ensure reproducibility in this example. \n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "a_true = -0.9594\n",
    "b_true = 7.294\n",
    "c_true = 3.102\n",
    "\n",
    "N = 25\n",
    "x = np.linspace(0, 10, N)\n",
    "\n",
    "yerr = 1 + 1 * np.random.rand(N)\n",
    "y = a_true * x ** 2 + b_true * x + c_true\n",
    "y += np.abs(y) * 0.1 * np.random.randn(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data created above is shown as a standard error bar plot below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.errorbar(x, y, yerr, marker='.', ls='', color='k')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create an `easyscience` analysis model. \n",
    "In this example, this consists of three parameters called `a`, `b`, and `c`.\n",
    "These parameters are created and initialised with the true values from above, they are all set with `fixed=False` as the parameters should be allowed to vary, to find the optimum solution -- the only one that maximises the likelihood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyscience.Objects.variable import Parameter\n",
    "\n",
    "a = Parameter(name='a', value=a_true, fixed=False)\n",
    "b = Parameter(name='b', value=b_true, fixed=False)\n",
    "c = Parameter(name='c', value=c_true, fixed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mathematical model that is to be optimised is\n",
    "```{math}\n",
    ":label: quadratic\n",
    "y = a x ^ 2 + b x + c.\n",
    "```\n",
    "\n",
    "To use `easyscience` to optimise this, a Python function that implements this mathematical model is needed. \n",
    "\n",
    "We can create a function that implements this mathematical model as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def math_model(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Mathematical model for a quadratic. \n",
    "    \n",
    "    :x: values to calculate the model over. \n",
    "    \n",
    "    :return: model values.\n",
    "    \"\"\"\n",
    "    return a.value * x ** 2 + b.value * x + c.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial guess (from the true value) for the mathematical model, along with the experimental data, can then be plotted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.errorbar(x, y, yerr, marker='.', ls='', color='k')\n",
    "plt.plot(x, math_model(x), '-')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimise the parameters `a`, `b`, and `c`, a `BaseObj` must be created. \n",
    "This brings together all parameters to be optimised in a single object, which is then associated with the mathematical model in the `Fitter`. \n",
    "Note that parameters that are fixed should not be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyscience.Objects.ObjectClasses import BaseObj\n",
    "from easyscience.fitting import Fitter\n",
    "\n",
    "quad = BaseObj(name='quad', a=a, b=b, c=c)\n",
    "f = Fitter(quad, math_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`easyscience` can then be used to determine the parameters of the quadratic model using {term}`maximum likelihood estimation` (MLE) .\n",
    "`y` describes the position of the normal distributions for the data while the `weights` are the reciprocals of their widths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = f.fit(x=x, y=y, weights=1/yerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the MLE found, the parameters can be printed to screen to see the optimized values and estimated statistical uncertainties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the optimised model can be plotted with the experimental data, using the same visualisation as [previously](./prob_data.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax[0].errorbar(x, y, yerr, marker='.', ls='', color='C0')\n",
    "ax[0].plot(x, math_model(x), '-', color='C1')\n",
    "ax[0].set_xlabel('$x$')\n",
    "ax[0].set_ylabel('$y$')\n",
    "\n",
    "y_range = np.arange(-22, 22, 0.1)\n",
    "for i, yy in enumerate(y):\n",
    "    ax[1].fill_between(y_range, norm(yy, yerr[i]).pdf(y_range), color='C0', alpha=0.02 * (i + 1), lw=0)\n",
    "    ax[1].plot(math_model(x[i]), norm(yy, yerr[i]).pdf(math_model(x[i])), 'C1o')\n",
    "ax[1].set_xlim(y_range.min(), y_range.max())\n",
    "ax[1].set_ylim(0, None)\n",
    "ax[1].set_xlabel('$y$')\n",
    "ax[1].set_ylabel('$p(y)$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach to use `easyscience` for the optimization of mathematical models can be applied to many different use cases, including in neutron scattering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
