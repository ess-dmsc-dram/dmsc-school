{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform priors in `easyscience`\n",
    "\n",
    "Bayesian methods are becoming more and more popular in the analysis of model-dependent data, in particular in neutron scattering. \n",
    "Thinking about data [probabilistically](./prob_data.ipynb), helps towards an understanding of Bayesian modelling.\n",
    "Bayesian modelling is about how to include prior knowledge about the system or parameters under study in the analysis. \n",
    "\n",
    "The same data as previously will be used again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "a_true = -0.9594\n",
    "b_true = 7.294\n",
    "c_true = 3.102\n",
    "\n",
    "N = 25\n",
    "x = np.linspace(0, 10, N)\n",
    "yerr = 1 + 1 * np.random.rand(N)\n",
    "y = a_true * x ** 2 + b_true * x + c_true\n",
    "y += np.abs(y) * 0.1 * np.random.randn(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The most straightforward way to include prior knowledge in some analysis is through the use of bounded parameters. \n",
    "Bounded parameters cannot have values less than some lower bound or greater than some upper bound, as the probability of the parameters having these values is zero. \n",
    "For example, if the parameter `b` from the quadratic model has bounds of 0 and 10, then there is an equal probability that the value of `b` can be anything in between 0 and 10, and a probability of 0 outside those bounds, i.e., it has a uniform prior probability distribution ({numref}`uniform`):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell",
     "dmsc-school-keep"
    ]
   },
   "source": [
    "<img src=\"uniform.png\" width=\"35%\">\n",
    "Figure 6: A uniform distribution (blue line), from 0 to 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "dmsc-school-remove"
    ]
   },
   "source": [
    "```{figure} uniform.png\n",
    "---\n",
    "width: 70%\n",
    "name: uniform\n",
    "---\n",
    "A normal distribution (blue line), centred on 10.4 with a standard deviation of 1.6.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Information about bounds can be included in `easyscience` parameters as `min` and `max` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from easyscience.Objects.variable import Parameter\n",
    "\n",
    "a = Parameter(name='a', value=a_true, fixed=False, min=-5.0, max=0.5)\n",
    "b = Parameter(name='b', value=b_true, fixed=False, min=0, max=10)\n",
    "c = Parameter(name='c', value=c_true, fixed=False, min=-20, max=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then perform the analysis in the same fashion as previously, however, this time the bounds will be respected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyscience.Objects.ObjectClasses import BaseObj\n",
    "from easyscience.fitting import Fitter\n",
    "\n",
    "def math_model(x, *args, **kwargs):\n",
    "    return a.value * x ** 2 + b.value * x + c.value\n",
    "\n",
    "quad = BaseObj(name='quad', a=a, b=b, c=c)\n",
    "f = Fitter(quad, math_model)\n",
    "\n",
    "res = f.fit(x=x, y=y, weights=yerr)\n",
    "\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently `easyscience` only supports uniform prior probability distributions, however, there are plans to extend this in the future. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
